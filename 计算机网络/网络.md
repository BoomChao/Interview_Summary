## HTTP

##### 何为HTTP

HTTP是超文本传输协议 (HyperText Transfer Protocol)

超文本：在互联网早期的时候文本只是简单的字符文字，但现在文本的含义已经可以扩展为图片，视频，压缩包等，在HTTP眼里这里都算作文本；超文本就是超越了普通的文件，它是文字，图片和视频等的混合体，最关键有超链接，能从一个超文本跳转到另外一个超文本

HTML就是最常见的超文本了，它本身只是纯文字文本，但内部使用了很多标签定义了图片，视频等链接，再经过浏览器的解释，呈现给我们的就是一个有文字有画面的网页了

HTTP 就是一个在计算机世界里专门在两点之间传输文字，图片，音频和视频等超文本数据的约定和规范

HTTP 有多个版本：目前主流的协议是HTTP1.1

http1.1 以下使用短连接，TCP发送端发送完信息等待接收到信息后就断开

http1.1 使用长连接，是**半双工通信**：一个连接可先后发送多个请求，但是回复按顺序一个一个回复

http2.0 是**全双工通信**，第一个消息发送后不用等待接收就可立即发送第二个消息

![](https://raw.githubusercontent.com/BoomChao/Windows_Figure/main/Image6.jpg) 

附：单工通信，半双工通信，全双工通信区别

单工通信：数据只能在一个方向上传输，同一时刻只能有一方接收或者发送消息，不能实现双向通信；如 电视，广播

半双工通信：允许数据在两个方向上传输，但是同一时刻只允许数据在一个方向上传输；如 对讲机

全双工通信：允许同一时刻数据在两个方向上同时传输；如 电话



##### HTTP常见字段

Host字段：客户端发送请求时，用来指定服务器的域名；有了host字段就可以将请求发往同一台服务器上的不同网站

Content-Length字段：服务器在返回数据时，会有Content-Length字段，表明本次回应的数据长度

Connection字段：常用于客户端要求服务器使用TCP持久连接，以便请求复用

Content-Type字段：用于服务器回应时，告诉客户端本次数据是什么格式的

Conten-Encoding字段：说明数据的压缩方法；表示服务器返回的数据使用了什么压缩格式



##### HTTP缺点

1.通信使用明文（不加密），内容可能会被窃听

2.不验证通信方的身份，因此可能遭遇伪装

3.无法验证报文的完整性，所以有可能已遭篡改

中间人攻击：请求或响应在传输途中，遭到攻击者拦截并篡改内容的攻击称为中间人攻击



##### HTTP1.1 相对于 HTTP1.0 的改进

HTTP协议是基于TCP/IP，并且使用了 请求-应答 的通信模式，所以性能的关键就在这两点里

1.长连接

​	早期HTTP性能一个很大的问题就是每发起一个请求，都要新建立一次TCP连接，而且是串行请求，做了无谓的TCP连接建立和断开，增加了通信开销；HTTP1.1提出了长连接的通信方式，也叫持久连接；这种方式的好处就是减少了TCP连接建立和释放所造成的额外开销，减轻了服务端的负载

持久连接的特点：只要一端没有明确提出断开连接，则保持TCP连接状态

2.管道网络传输

   HTTP1.1采用长连接的方式，这使得管道网络传输成为了可能；即在同一个TCP连接里，客户端可以发起多个请求，不必等待其回来，就可以发送第二个请求，这样减少整体的响应时间

比如客户端需要请求两个资源；以前的做法是在同一个TCP连接里面，先发送A请求，然后等待服务器做出回应，收到后再发送B请求；管道机制则是允许浏览器同时发出A请求和B请求

但是服务器还是按照顺序先回应A请求，再回应B请求；要是前面的回应特别慢，后面就会有很多请求排队等着，这就叫队头阻塞

3.会导致队头阻塞



##### HTTP2.0相比于HTTP1.1的改进

1.多路复用

   HTTP2.0使用了多路复用的技术，做到同一个连接并发处理多个请求，而且不需要像HTTP1.1那样需要按照请求顺序来回应，并且并发请求的数量比HTTP1.1大了好几个数量级。HTTP1.1也可以多建立几个TCP连接，来支持处理更多并发的请求，但是创建TCP连接本身也是有开销的

2.头部数据压缩

   在HTTP1.1中，HTTP请求和响应都是由开始行、首部行、消息主体三部分组成。一般而言，消息主体都会经过gzip压缩，或者本身传输的就是压缩过后的二进制文件，但开始行和首部行却没有经过任何压缩，直接以纯文本传输。随着Web功能越来越复杂，每个页面产生的请求数也越来越多，导致消耗在头部的流量越来越多，尤其是每次都要传输UserAgent、Cookie这类不会频繁变动的内容，完全是一种浪费

HTTP1.1不支持 header 数据的压缩，HTTP2.0使用HPACK算法对header的数据进行压缩，这样数据体积小了，在网络上传输就会更快

HPACK算法就是在客户端和服务器中同时维护⼀张相同的头信息表，所有字段都会存入这个表，生成⼀个索引号，以后就不发送同样字段了，只发送索引号，这样就提高速度了

3.服务器推送

   服务端推送是一种在客户端请求之前发送数据的机制。网页使用了许多资源：HTML、样式表、脚本、图片等等。在HTTP1.1中这些资源每一个都必须明确地请求。这是一个很慢的过程。浏览器从获取HTML开始，然后在它解析和评估页面的时候，增量地获取更多的资源。因为服务器必须等待浏览器做每一个请求，网络经常是空闲的和未充分使用的

为了改善延迟，HTTP2.0引入了server push，它允许服务端推送资源给浏览器，在浏览器明确地请求之前，免得客户端再次创建连接发送请求到服务器端获取。这样客户端可以直接从本地加载这些资源，不用再通过网络



HTTP2.0的一个主要缺点就是多个 HTTP 请求在复用⼀个 TCP 连接，下层的 TCP 协议是不知道有多少个 HTTP 请求的；所以⼀旦发生了丢包现象，就会触发 TCP 的重传机制，这样在⼀个 TCP 连接中的所有的 HTTP 请求都必须等待这个丢了的包被重传回来；所以HTTP3.0就直接把HTTP底层的协议换成了UDP



##### 1.HTTP和HTTPS的区别，HTTPS怎么保证安全性的以及HTTPS有什么缺点？为什么要采用非对称和对称加密结合？     

**答：**https 是在 http 的基础上使用了安全套接字 SSL(Secure Socket Layer)；SSL工作在应用层和传输层之间

https使用加密技术对传输的数据进行加密，致使数据在网络上传输更加安全； 

刚开始时采用非对称加密协商好对称加密的密钥，之后传输数据都用对称加密；

非对称加密密钥在网上传输安全，不怕被截获，但是加密效率低；对称加密密钥在网上传递不安全，但对称加密效率高；https即结合了对称加密和非对称加密的优点

https缺点：

1.https握手阶段延时较高：由于在进行http会话之前还要进行SSL握手(就是SSL会话的建立)，因此https协议握手阶段延时增加

2.https部署成本高：一方面 https 协议需要使用证书来验证自身的安全性，所以需要购买CA证书；另一方面由于采用https协议需要进行加解密的计算，占用CPU资源较多，间接加重了服务器的负担，降低了用户的访问速度，所以对服务器配置数目要求高

区别：

1.HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。 HTTPS 则解决 HTTP 不安全的缺陷，在TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输

2.HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握⼿之后，还需进行 SSL/TLS 的握手过程，才可进⼊加密报文传输

3.HTTP 的端口号是 80， HTTPS 的端口号是 443

4.HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的

5.HTTP是应用层协议，而HTTPS不是应用层的一种新协议，只是将HTTP通信接口部分使用 SSL (Secure Socket Layer) 和 TLS (Transport Layer Security) 代替而已     

SSL：安全套接字层     TLS：安全传输层协议

注：建立一个HTTPS连接需要握手7次，TCP层握手3次， SSL层握手4次

HTTPS是应用层协议，需要先完成TCP连接建立，然后走TLS握手过程，才能建立安全的连接



##### 2.试阐述https建立连接的过程       

**答：**https是在http协议的基础上使用了SSL安全套接字层，SSL工作在应用层和传输层之间（注：https建立连接的过程就是SSL建立安全会话的过程  计网P346）

比如我现在客户机用浏览器访问一个提供安全在线购物的网站B；当我点击该网站连接建立TCP连接后，先进行浏览器和网站服务器之间的握手协议，完成加密算法的协商和会话密钥的传递，然后进行数据的安全传输；大概流程如下：

1.协商加密算法：浏览器A向服务器B发送浏览器的SSL版本号和一些可选的加密算法；B从中选出自己支持的加密算法 (如RSA)，并告知A

2.服务器鉴别：服务器B向浏览器A发送包含其RSA公钥的数字证书；A使用该证书的认证机构CA公开发布的公钥对该证书进行验证

3.会话密钥计算：由浏览器A随机产生一个秘密数；用浏览器的RSA密钥加密后发送给B；双方根据协商的算法产生共享的对称对话密钥

4.客户端会再发送一个消息，也就是把之前发送的数据都做个摘要，再用会话密钥加密一下，让服务器做个验证，验证加密通信是否可用和之前的握手信息是否有被中途篡改过，服务端收到后也做同样的操作，如果双方加密和解密都没有问题，那么SSL层握手就正式完成

5.数据安全传输：双发使用对称会话密钥加密和解密它们之间传送的数据并验证其完整性

注意：上面第二步服务器鉴别过程中，证书里面的内容其实就是**服务器的公钥**和**证书认证机构对该公钥的数字签名** (数字签名就是用私钥加密的数据，这个数据就是公钥；私钥加密公钥也可以解开)

浏览器得到证书后，用CA的公钥对其中的数字签名进行校验，看结果和公钥符不符合，符合就表明通信的对方确实是真实的

附：公钥存放在哪里？

**答：**公钥存放在服务器上，公钥可随意传播；

而证书理论上应该存放在CA服务器上，但是现在一般都是存放在服务端上，直接由服务端发送给客户端进行校验，因为如果存放在CA服务器上，那么客户端除了要与服务端建立连接外，还需要和CA服务器端建立连接，这样太麻烦



##### 3.对称加密和非对称加密的性能差多少？为什么对称加密性能高

**答：**加密算法的性能取决于加密算法所进行的加解密运算

对于对称加密，因为对称加密主要的运算是位运算，速度非常快，如果使用硬件来计算，速度会更快，拿AES对称加密算法为例，其运算本质上是移位和替换

非对称加密算法的计算一般都比较复杂，如RSA，它里面涉及到大数乘法，大数取模等运算，效率相比于位运算很低



##### 4.常见的几种加密算法

**答：**

1、非对称加密算法 RSA

是一个支持变长密钥的公共密钥算法，需要加密的文件块的长度也是可变的，RSA加密算法是目前最具影响力的公钥加密算法，它是第一个能同时用于加密和数字签名的算法

RSA加密算法基于一个十分简单的数论事实：将两个大 素数 相乘十分容易，但想要对其乘积进行 因式分解 却极其困难，因此可以将 乘积 公开作为 加密密钥

2、对称加密算法 DES/3DES/AES

DES（Data Encryption Standard）：对称加密算法，数据加密标准，速度较快，适用于加密大量数据的场合

DES 加密算法是一种 分组密码，以 64 位为分组对数据加密，它的 密钥长度 是 56 位，加密解密用同一算法

DES 加密算法是对 密钥 进行保密，而 公开算法，包括加密和解密算法。这样，只有掌握了和发送方 相同密钥 的人才能解读由 DES加密算法加密的密文数据。因此，破译 DES 加密算法实际上就是 搜索密钥的编码。对于 56 位长度的 密钥 来说，如果用 穷举法 来进行搜索的话，其运算次数为 2 ^ 56 次

3DES算法是基于 DES 的 对称算法，对 一块数据 用 三个不同的密钥 进行 三次加密，强度更高

AES 加密算法是密码学中的 高级加密标准，该加密算法采用 对称分组密码体制，密钥长度最少支持为 128 位、 192 位、256 位，分组长度 128 位，算法应易于各种硬件和软件实现；这种加密算法是美国联邦政府采用的 区块加密标准

AES 本身就是为了取代 DES 的，AES 具有更好的 安全性、效率 和 灵活性

3、消息摘要算法 MD5

MD5：严格来说不算加密算法，只能说是摘要算法，属Hash算法一类。MD5算法对输入任意长度的消息进行哈希运算，产生一个128位的消息摘要 (32位的数字字母混合码)；

不可逆：相同数据的MD5值肯定一样，不同数据的MD5值不一样

压缩性：任意长度的数据，算出的MD5值长度都是固定的 (相当于超损压缩)

容易计算：从原数据计算出MD5值很容易

抗修改性：对原数据进行任何改动，哪怕只修改1个字节，所得到的MD5值都有很大区别。

**注：**MD5明文加密不安全，因为可以使用穷举法对密文进行穷举，最终得到一个和密文一样的字符串，从而得到明文的密码可通过引进干扰项(salt，也称之为加盐)，就是先对密码加入一串字符串作为干扰项，然后进行MD5加密得到一个32位的字符串，这样即使别人暴力破解了，由于存在干扰项也不会知道原文密码



中间人攻击：请求或者响应在传输途中遭到攻击者拦截并篡改内容的攻击就称为中间人攻击

数据加密可以有效的避免中间人攻击



##### 5.请说一说HTTP的返回码  

**答：**状态码都是３位数字，分为５大类	（这里的返回码指的就是HTTP响应报文中的状态码）  （计网P272）

1xx表示通知信息，如请求收到了或正在处理    

2xx表示成功，如接收或者知道了                  

3xx表示重定向，资源位置发生变动，如完成请求还必须采取进一步的行动，也就是需要客户端重新发送请求  

4xx表示客户端的差错，如请求中有错误的语法或者不能完成  

5xx表示服务器的差错，如服务器失效无法完成请求       

100 Conintue：客户端应继续请求

200 OK：表示请求已经完成       204 No Content：与200Ok基本相同，但是响应头没有body数据



301 Moved Permanently（**永久重定向**），请求的资源的已经被永久移动到新URL，返回的信息会包括新的URL，浏览器会自动定向到新的URL

302 Found（**临时重定向**），说明请求的资源还在，但暂时需要用一个新的URL来访问

301 和 302 都会在响应头里使用字段 Location ，指明后续要跳转的 URL，浏览器会⾃动重定向新的 URL

304 Not Modified：不具有跳转的含义，表示资源未修改，重定向已存在的缓存⽂件，也称**缓存重定向**，⽤于缓存控制



400 (Bad Request) 表示错误的请求	403 (Forbiden)表示没有访问资源的权限  	 404 (Not Found)表示找不到请求资源   	499表示客户端主动断开连接



500(Internal Server Error)：服务器内部错误，无法完成请求，这只是个笼统的错误码，具体什么错误不从得知   

502(Bad Gateway)：表示网关错误，从服务器接收到无效的响应

504(GateWay Time-out) : 作为网关或者代理工作的服务器尝试请求时，由于等待响应超时，未能及时从上游服务器收到响应



HTTP断点续传：断点续传返回的状态码是206

断点续传就是从文件上次中断的地方开始重新下载或上传，当下载或上传文件的时候，如果没有实现断点续传功能，那么每次出现异常或者用户主动的暂停，都会去重头下载，这样很浪费时间；所以断点续传的功能就应运而生了

想要实现断点续传的功能，就需要客户端记录下当前的下载或上传进度，并在需要续传的时候通知服务端本次需要下载或上传的内容片段

附：如果续传的过程中文件变化了，怎么判断呢？

**答：**会有一个字段记录文件的最后修改时间，服务器会检查这个字段，如果不符合则会重新从头发送 (返回状态码200)



##### 6.说一说http的发送请求的报文都有什么？  

**答：**http请求报文和响应报文都是由三部分组成：开始行，首部行，实体主体	（计网P271）

在请求报文中的开始行叫做请求行，请求行里面只有三个内容 方法，请求资源的URL和HTTP的版本；

在响应报文中的开始行叫做状态行，状态行包括HTTP的版本，状态码以及解释状态码的简单短语

首部行是用来说明浏览器、服务器或报文主体的一些信息

在请求报文中一般不需要实体主体，而在响应报文中也可能没有这个字段



##### 7.Get 和 Post 的区别？

**答：**Get 和 Post 是HTTP协议的两种发送请求的方法，HTTP是基于TCP/IP的关于数据如何在万维网中通信的协议；HTTP底层是TCP/IP，所以说 Get 和 Post 都是TCP连接

Get 方法用来请求访问已被 URI 识别的资源，指定的资源经服务端解析后返回响应内容

Post 方法用来传输实体的主体；虽然用Get方法也可以传输实体的主体，但一般不用Get方法传输，而是使用 Post 方法；虽说 Post 的功能与 Get 很相似，但是Post 的主要目的并不是获取响应的主体内容 （《图解HTTP》P28）

| 操作方式 | 数据位置 | 明文密文 | 数据安全 | 长度限制         | 应用场景 |
| -------- | -------- | -------- | -------- | ---------------- | -------- |
| Get      | HTTP包头 | 明文     | 不安全   | 长度较小         | 查询数据 |
| Post     | HTTP正文 | 密文     | 安全     | 支持较大数据传输 | 修改数据 |



附：Get 和 Post 方法都是安全和幂等的吗？

**答：**在HTTP协议里，安全是指请求方法不会破坏服务器上的资源；幂等就是多次执行相同的操作结果都是相同的

Get 方法是安全且幂等的，因为它是只读操作，不会对服务器上的资源进行更改

Post 方法是新增或者提交数据，会修改服务器上的资源，自然也就不是安全和幂等的



##### 8.cookie和session

**答：**cookie 的出现是因为 HTTP 是无状态的一种协议，换句话说就是服务器是记不住你的，可能你每刷新一次网页，就要重新输入一次账号密码登录；而cookie的作用就好比服务器给你贴一个标签，然后你再次登录服务器时，服务器就能够通过 cookie 认出你

但是有的网站很复杂，存储的用户的信息也很多，无法通过一个 cookie 来存储太多信息，而且 cookie 字段是存储在HTTP头部的，就算能够承载这么多的信息也会十分的消耗带宽，比较消耗网络资源；session 就可以配合 cookie 解决这一问题，比如 cookie 存储这样一个变量，sesssion ID = xxx，仅仅把这样一个 cookie传给服务器，然后服务器就通过这个 ID 找到对应的 session，这个 session 是一个数据结构，里面存储着用户的购物车等详细信息，服务器就可以通过这些信息返回该用户的定制化网页，有效解决了用户追踪的问题

cookie 可以认为一个变量，存储在浏览器上

session 是一个数据结构，多数情况下是一个映射 (键值对)，存储在服务器上，session 可以存储各种数据，只要客户端的 cookie 传来一个唯一的 session ID，服务器就能找到对应的 session，从而认出这个客户



## 应用层

##### 1.本地域名服务器向根服务器查询的是什么？

**答：**根服务器不负责具体的域名解析，但是根服务器知道每个具体的域名解析的服务器的地址，即知道.com域名是由哪个服务器来进行解析，.org，.edu又是由哪些服务器进行解析

所以本地域名服务器向根服务器查询的是其他DNS服务器的地址

比方说现在我输入的是 www.dlut.edu ，但是本地服务器解析的是.com的域名，这时就会向根服务器请求查询解析.edu域名的服务器，根服务器将查询结果返回给本地服务器后，本地服务器再根据结果访问目标服务器



##### 2.域名解析的过程

**答：**比方说我现在输入的网址是 [www.baidu.com](http://www.dut.com/) ，如果本地域名解析服务器解析的是.com的域名，则本地服务器会直接将查询到的IP地址返回给主机，主机拿到IP地址后按照IP地址访问

但是如果本地域名服务器解析的不是.com的域名，那么本地域名服务器就会向根服务器请求查询解析.com域名的服务器，根服务器将查询结果返回给本地服务器后，本地服务器再根据结果访问目标服务器；目标服务器将解析到的域名的结果返回给本机，本机拿到IP地址后按照地址访问



##### 3.域名解析过程，本机如何干预域名解析

**答：**在进行域名解析的过程时，首先查询本地域名服务器，也就是 ISP 提供的DNS服务器，如果找不到，这时候就有两种查询方式：递归查询和迭代查询

1.**主机向本地域名服务器的查询一般都是采用递归查询**（recursive query)；如果主机所查询的本地域名服务器不知道被查询域名的IP，则本地域名服务器就以DNS客户端的身份，向其他根域名服务器发出请求报文(即代替该主机继续查询)，而不是让该主机自己进行下一步查询；因此递归查询返回的是查询结果也就是要查询到的目标IP，或者是报错，表示无法查询到所需要的IP地址

2.**本地域名服务器向根域名服务器发出查询通常是采用迭代查询**（iterative query)；迭代查询的特点是：当根域名服务器收到本地域名服务器的迭代请求报文时，要么给出要查询的IP地址，要么告诉本地服务器："你下一步应当向哪一个域名服务器进行查询"。根域名服务器通常是把自己知道的顶级域名服务器的IP地址告诉本地域名服务器，让本地域名服务器再向顶级域名服务器查询；顶级域名服务器在收到本地域名服务器的查询请求后，要么给出所要查询的IP地址，要么告诉本地域名服务器下一步应当向哪一个权限域名服务器进行查询；本地域名服务器就这样进行迭代查询，最后知道了所要解析的域名的IP地址，然后把这个结果返回给发出查询的主机

通俗来说：(1) 递归就是把一件事交给别人，如果事情没做完，哪怕已经办了很多，都不要把结果告诉我，我要的是你的最终结果，而不是中间结果；如果你没办完，请找别人帮你办完

(2) 迭代就是我交给你一件事，你能办多少就告诉我你办了多少，然后剩下的事情就由我来办

![](https://raw.githubusercontent.com/BoomChao/Windows_Figure/main/Image22.png) 





##### 4.什么命令可以通过域名查IP呢？

**答：**两种方法

1.ping命令用来测试网络是否畅通；可以 ping [www.baidu.com](http://www.baidu.com/)会先显示域名对应的IP地址

2.nslookup命令用来查询目标域名和其对应的主机IP地址；它通常需要一个域名解析服务器来提供域名服务；

如 nslookup [www.baicu.com](http://www.baicu.com/) 显示的结果第一条为使用的域名解析服务器的地址；第二条为目标域名对应的IP地址



##### 5.浏览器访问网站用到哪些协议？

**答：**在浏览器搜索baidu,会用到计算机网络中的哪些层？每层是干什么的？输入一个URL发生了什么？都是下面这个回答

浏览器要将URL解析为IP地址，解析域名就要用到DNS协议，首先主机会查询DNS的缓存，如果没有就给本地DNS服务器发送查询请求；得到IP地址后，浏览器就要与服务器建立一个http连接；http生成一个get请求报文，将该报文传给TCP层处理 (如果需要加密则使用https协议)， TCP的数据包发送给IP层，IP层通过路由选路，一跳一跳发送到目的地址；当然在同一个网段内的寻址是通过以太网协议来实现的，以太网协议需要知道目标IP地址的物理地址，所以又需要ARP协议

其中：

1.DNS协议，HTTP协议，HTTPS协议属于应用层       

应用层是体系结构中的最高层；应用层确定进程之间通信的性质以满足用户的需要；这里的进程指的是正在运行的程序；应用层不仅要提供应用程序所需要的信息交换和远地操作，而且还要作为互相作用的应用进程的用户代理，来完成一些进行语义上有意义的信息交换所必须的功能；应用层直接为用户的的应用进程提供服务

2.TCP/UDP属于传输层    （负责可靠传输或者不可靠传输）

传输层的任务就是负责主机中两个进程之间的通信；因特网的传输层可使用两种不同的协议：即面向连接的传输控制协议TCP和无连接的用户数据报协议UDP；面向连接的服务能够提供可靠的交付，但无连接的服务则不能提供可靠的交付，它只是 "尽最大努力的交付"

3.IP协议，ARP协议属于网络层     （网络层负责选择最佳路径，规划IP地址）

网络层负责为分组交换网的不同主机提供通信；在发送数据时，网络层将传输层产生的报文段或用户数据报封装成分组或包进行传送；在TCP/IP体系中，分组也叫做IP数据报，或简称为数据报；网络层的另一个任务是要选择合适的路由，使源主机运输层所传下来的分组能够交付到目的主机

4.数据链路层     （数据链路层定义了数据帧的开始和结束，实现透明传输并且有差错校验功能）

当发送数据时，数据链路层的任务是将在网络层交付下来的IP数据报组装成帧，在两个相邻节点间的链路上传送以帧为单位的数据；每一帧包括数据和必要的控制信息 (如同步信息、地址信息、差错信息、以及流量控制信息等)；控制信息使接收端能够知道一个帧是从哪个比特开始到哪个比特结束；控制信息还使接收端能够检测到所接收的帧中有无差错

5.物理层     （定义一些物理标准如电器电压网线标准等）

物理层的任务是透明的传输比特流；在物理层上所传数据的基本单位是比特；传递信息所使用的一些物理媒介，如双绞线、同轴电缆、光纤等并不在物理层之内而是在物理层的下面；因此也有人把物理媒介当作第0层



##### 6.如果浏览器打开某个网站比较慢(但是打开其他网站没有问题)，怎么分析问题？怎么优化？

**答：**可能是三个原因

1.网站服务器速度或者租用服务商服务器速度

服务器速度是网站打开的速度快的硬件基础，也是先决条件；否则即使你网站页面设计的非常"苗条"，网站打开速度也会大打折扣；

解决方法：需要找服务商解决或者更换服务商

2.电信和联通机房互访瓶颈问题

如果网站打开速度时快时慢，甚至有时打不开，那就是空间服务商不稳定的问题；需要找服务商解决；如果在有的地方打开速度快，有的地方打开速度慢，则应该是网络线路的问题；电信线路用户访问在联通服务器的网站，联通线路访问在电信服务器的网站，相对而来打开速度肯定是比较慢

解决方法：如果购买空间的话，建议购买双线空间或者多线空间 ( 通俗点就是电信和联通的服务机房都布置网站的服务器 )

3.网站本身的问题

网站的问题包括网站程序设计，网页结构设计，网页内容三个部分

解决方法：找前端人员排查



##### 7.网络中常见的攻击有哪些？

**答：**网络攻击主要分为被动攻击和主动攻击（计网P324）

被动攻击是指攻击者从网络上窃取他人的通信内容；通常把这类攻击叫做截获；在被动攻击中，攻击者通常只是观察和分析某一个协议数据单元 (PDU) 而不干扰信息流

主动攻击有以下三种方式

1.篡改：攻击者故意修改网络上的报文再发送给接收方

2.恶意程序：包括病毒，木马，流氓软件等

3.拒绝服务攻击 (Dos攻击)：指攻击者向互联网上的某个服务器不停的发送大量数据分组，使得该服务器无法正常提供服务，甚至完全瘫痪；若是从互联网的成百上千的网站集中攻击一个网站，则称为分布式拒绝服务攻击 (DDos攻击)

总结：被动攻击一般检测不出来，主动攻击可采取适当措施防范



**附：避免SYN攻击的几种方式 （小林266）**

**答：**服务端的 Socket 会在内核中维护两个队列，一个称为半连接队列 (也叫SYN队列)，这里面的连接都是还没有完成三次握手的连接，另外还有一个全连接队列 (Accept 队列)，这里面的连接都是已经完成三次握手的连接

**方法一：**其中⼀种解决方式是通过修改 Linux 内核参数，控制半连接队列大小和当队列满时应做什么处理，比如队列满时直接对新到来的连接发送 RST 包，不允许建立连接；但是这种方式实现比较困难，因为修改内核参数想再使其生效需要重新编译 Linux 内核

**方法二：**如果不断受到 SYN 攻击，则很容易导致半连接队列被占满，当半连接队列满时，后续的数据包不再进入半连接队列

TCP 有一个 syncookie 功能，当开启了 syncookie 就可以在不使用半连接队列的情况下成功建立连接

syncookie 服务器根据当前状态计算出⼀个值，放在己方发出的 SYN+ACK 报文中发出，当客户端返回 ACK 报⽂时，取出该值验证，如果合法，就认为连接建⽴成功，将连接放入accept 队列中

syncookie 参数主要有以下三个值：

0值：表示关闭该功能；	1值：表示仅当SYN半连接队列满时，再启动 syncookie，所以防御 SYN 攻击可以将该参数设置为1

2值：表示无条件开启该功能

**方法三：**减少 SYN+ACK 重传次数

当服务端受到 SYN 攻击时，就会有大量处于 SYN_REVC 状态的 TCP 连接，处于这个状态的 TCP 会重传 SYN+ACK ，当重传超过次数达到上限后，就会断开连接；那么针对 SYN 攻击的场景，我们可以减少 SYN+ACK 的重传次数，以加快处于 SYN_REVC 状态的 TCP 连接断开



**附：常见的几种web攻击**

简单的 HTTP 协议本身并不存在安全问题，因此协议本身几乎不会成为攻击的目标；而应用 HTTP 协议的服务器和客户端，以及运行在服务器上的Web应用等资源才是攻击的目标

目前来自互联网的攻击大多都是冲着Web站点来的，它们把 Web 应用作为攻击目标

1.跨站脚本攻击  (Cross-Site Scripting，XSS) 是通过存在安全漏洞的 web 网站注册用户的浏览器内运行非法的 HTML 标签或者 JavaScript 进行的一种攻击；动态创建的 HTML 部分有可能隐藏着安全漏洞，就这样，攻击者编写脚本设置陷阱，用户在自己的浏览器上运行时，一不小心就会受到被动攻击

2.SQL注入攻击是指针对 web 应用使用的数据库，通过运行非法的 SQL语句 而产生的攻击；web 应用通常都会用到数据库，当需要对数据库中的表进行增删改查操作时，会使用 SQL 语句连接数据库进行特定的操作；如果在调用 SQL 语句的方式上存在疏漏，就有可能执行被恶意注入的非法 SQL 语句

3.OS 注入攻击是指通过 web 应用，执行非法的操作系统命令达到攻击的目的；只要是在能调用 shell 的函数的地方就存在被攻击的风险；可以从 web 应用中通过shell 调用操作系统命令，倘若调用 shell 时存在疏漏，就可以执行插入的非法 OS 命令

4.HTTP 首部注入攻击是指攻击者通过在响应首部字段插入换行，添加任意响应首部或主体的一种攻击





## 传输层

#### TCP/IP四层模型

为了使多种设备 (如 网卡，交换机，路由器) 能够通过网络互相通信，和为了解决各种不同设备在网络中的兼容性问题，才有了OSI参考模型，各层职能如下：

应用层：负责给应用程序提供统⼀的接口

表示层：负责把数据转换成兼容另⼀个系统能识别的格式；

会话层：负责建立、管理和终止表示层实体之间的通信会话；

传输层：负责端到端的数据传输；

网络层：负责数据的路由、转发、分片；

数据链路层：负责数据的封装成帧和差错检测，以及 MAC 寻址；

物理层：负责在物理网络中传输数据帧



由于OSI参考模型太过复杂，提出的也只是概念上的分层，并没有具体的实现；事实上比较实用的是 TCP/IP 四层模型

TCP/IP 模型共四层，分别是应用层，传输层，网络层和网络接口层

应用层：负责向用户提供⼀组应用程序，比如 HTTP、 DNS、 FTP 等;

传输层：负责端到端的通信，比如 TCP、 UDP 等；

网络层：负责网络包的封装、分片、路由、转发，比如 IP、 ICMP 等；

网络接口层：负责网络包在物理网络中的传输，比如网络包的封帧、 MAC 寻址、差错检测，以及通过网卡传输网络帧等



#### TCP三大特性

TCP的三个特点来保证可靠性：1.可靠传输  2.流量控制  3.拥塞控制

首先TCP传输是需要建立会话的，保证可靠的连接是保证可靠性的前提

1.可靠传输就是指TCP的超时重传机制和滑动窗口机制

2.流量控制就是指TCP通过改变传输窗口的大小来限制传输的速率，让发送方不要发送的太快

3.拥塞管理就是指在拥塞避免阶段把拥塞窗口控制为按线性规律增长，使得网络比较不容易出现拥塞；利用的是慢开始和拥塞避免算法



问：拥塞控制和流量控制的区别 （计网P230）

**答：**拥塞控制就是防止过多的数据注入到网络中，这样就可以使网络中的路由器或者链路不致于过载；拥塞控制所要做的都有一个前提，就是网络中能够承受现有的网络负荷；拥塞控制是一个全局的过程，涉及到所有的主机，所有的路由器以及降低网络传输性能相关的所有因素

流量控制往往是指点对点通信量的控制，是个端到端的问题（接收端控制发送端）；流量控制所要做的就是抑制发送端发送数据的效率，以便接收端来得及接收



##### 可靠性

TCP通过以下方式来进行保证可靠性：

1.数据包校验：目的是检测数据在传输过程中的任何变化，若检验包有错，则丢弃报文段并且不给出响应，这时TCP发送数据端超时后会重新发送数据

2.对失序数据报重排序：既然 TCP 报文段作为 IP 数据报来传输，而 IP 数据报的到达可能会失序，因此 TCP 报文段的到达也可能会失序；TCP将对失序的数据进行重新排序，然后再交给应用层

3.丢弃重复数据：对于重复数据，能够丢弃重复数据

4.应答机制：当TCP收到发自TCP连接另一端的数据，它将发送一个确认；这个确认不是立即发送，通常将推迟几分之一秒

5.超时重发：当TCP发出一个报文段后，它启动一个定时器，等待目的端确认收到这个报文段；如果不能及时收到一个确认，将重发这个报文段

6.流量控制：TCP连接的每一方都有固定大小的缓存空间；TCP的接收端只允许另一端发送接收端缓冲区所能接纳的数据，这可以防止较快主机致使较慢主机的缓冲区溢出，这就是流量控制；TCP使用的流量控制协议是可变大小的滑动窗口协议

7.拥塞控制



##### 流量控制

1.试阐述ARQ协议的原理和过程                               （注：现在都是利用连续的ARQ协议，原理是流水线传输）

**答：**发送方发送一个数据分组，等到接收方接收到数据分组后返回一个确认的消息，这时发送方才发送第二个数组分组，以此来实现可靠传输；要是发送方没有收到接收方返回的确认的消息，发送方会自动再发一次数据分组，但是这种**重传的请求是自动进行的，接收方不需要发送请求给发送方来要求重传某个出错的分组**

附：通俗一点就是说，我发送给你数据，你收到了就给我回复；不给我回复我就认为你没收到，我再发一遍



71.TCP滑动窗口用什么技术实现的？  2.请阐述滑动窗口协议原理和过程       （滑动窗口协议也叫连续ARQ协议）

**答：**回答这个问题之间先要阐述一下什么是流水线传输

如果发送方发送一个数据包等到接收方回复后再发送下一个数据包，这样的话信道利用率太低；为了提高信道利用率，现在采用的是**流水线传输**；发送方可连续发送多个分组，不必每发完一个分组就停顿下来等待确认；这种发送方式由于信道上一直都有数据不间断的传送，所以可以获得很高的信道利用率

滑动窗口协议就是利用的流水线传输的原理

过程：可以假设滑动窗口是5，则一次性连续的发送5个数据分组，发送完后再等待确认，如果收到了第一个数据包的确认，则滑动窗口自动往前移，这时第6个数据分组也在滑动窗口中，将其发送出去，也就是发送->收到回复->窗口前移->发送->收到回复->窗口前移…… 这么一个连续的过程



##### 拥塞控制

56.具体讲讲拥塞控制

**答：**TCP的拥塞控制是基于窗口的拥塞控制；发送方维持一个叫做拥塞窗口的状态量；拥塞窗口的大小取决于网络的拥塞程度，并且动态的在变化；发送方让自己的发送窗口等于拥塞窗口

发送方控制拥塞窗口的原则是：只要网络没有出现拥塞，拥塞窗口就可以再增大一些，以便把更多的分组发出去，这样就可以提高网络的利用率；但只要网络出现拥塞或者有可能出现拥塞，就必须把拥塞窗口减小一些，以便减少注入到网络中的分组数，从而缓解网络中出现的拥塞

具体的拥塞窗口控制的四个算法为：慢开始算法、拥塞避免算法、快重传算法、快恢复算法

当网络出现了拥塞时，路由器就要丢弃分组；因此只要发送方没有按时收到应当到达的确认报文，也就是说只要出现了超时，就可以猜想网络出现了拥塞；因此，判断网络出现拥塞的依据就是超时



54.拥塞控制的四个算法？     （RRT : round-trip-time）

**答：**拥塞控制的四个算法：慢开始(slow-start)，拥塞避免(congestion avoidance)，快重传(fast retransmit)，快恢复(fast recovery)

**慢开始算法**的思路：当主机开始发送数据时，由于并不清楚网络的负荷情况，如果立即把大量的数据字节注入到网络，那么很有可能会引发网络发生拥塞；最好的方法是先试探一下，再由小到大逐渐增加拥塞窗口数值；慢开始算法每经历一个往返时间RRT（也可以说每经历一个传输轮次），拥塞窗口cwd就加倍

**拥塞避免算法**的思路：让拥塞窗口 cwd 缓慢增大，即每经过一个往返时间RRT就把发送方的窗口加1；拥塞避免算法就是把拥塞窗口控制为按线性规律增长

< 慢开始门限 (ssthresh) 时使用慢开始算法，> ssthresh 使用拥塞避免算法；= ssthreash 两种算法都可以使用

有时个别报文段会在网络中丢失，但实际上网络并没有发生拥塞；如果发送方迟迟收不到确认，就会产生超时，就会误认为网络发生了拥塞；这就导致发送方错误地启动慢开始算法并把拥塞窗口又设置为1，因而降低了传输效率

**快重传算法**首先要求接收方不要等待自己发送响应数据时再进行捎带确认，而是要立即发送确认，即使收到了失序的数据包也要立即发出对已收到报文段的重复确认

其快重传算法规定只要发送方一连收到3个重复确认，就知道中间存在数据包丢失，发送方立即重传丢失的数据包，这样就不会出现超时，发送方也就不会误认为出现了网络拥塞

**快恢复算法**就是当发送方现在知道只是丢失了个别的数据包，正常来说如果发送方发现丢失了大量数据包就说明网络堵了，发送方就应该启动慢开始算法并重新调整门限值和拥塞窗口，但是现在只是少量数据包丢失，于是发送方执行快恢复算法，调整门限值和拥塞窗口执行拥塞避免算法  （因为如果启动慢开始算法则拥塞窗口会被重置为1）

快恢复算法把门限值调整为拥塞窗口的一半；也有的会增大拥塞窗口     （《计网》P235）

附：门限值单位是字节，只不过书上为了讲清原理用数据包个数来代替这样方便理解



##### TCP连接建立和断开：

50.TCP为什么被称为流式传输协议？你怎么定义流？  （计网P211）

**答：**TCP中的流是指流入到进程或者从进程流出的字节序列；

面向字节流的含义是：虽然应用程序和TCP的交互是一次一个数据块，但是TCP把应用程序交付下来的数据仅仅看成是一连串的无结构的字节流；TCP并不知道所要传输的字节流的含义，TCP不保证接受端应用程序所收到的数据块和发送方应用程序所发出的数据块具有对应大小的关系 (比如：发送方应用程序交给发送方的TCP共10个数据块，但接收方的TCP可能只用了4个数据块就把收到的字节流交付给上层的应用程序)，但是接收方应用程序收到的字节流必须和发送方应用程序发出的字节流完全一样



10.TCP三次握手是否都可以携带数据？

**答：**第一次和第二次不能携带数据

假如第一次握手可以携带数据的话，那对于服务器而言太危险了，如果有人恶意攻击服务器，在第一次握手的 SYN 报文中放入大量数据，而且频繁重复发送 SYN 报文，那么服务器就会花费很多时间去处理这些报文

第二次握手是服务器回给客户端的响应报文，表示同意建立连接，没有数据携带

第三次握手可以携带数据，因为此时客户端已经处于ESTABLISHED状态了，对于客户端来说，它已经建立连接了，并且知道服务器的接收和发送能力是正常的；所以也就可以携带数据了

附：TCP三次握手前两次的序列号为主机和服务器自己选的一个值，没有说一定要使用哪个值

TCP四次挥手前两次的序列号为上一次已经传送过的数据的最后一个字节的序号加1



11.三次握手中的报文丢失了怎么处理？

**答：**

1.第一次握手SYN报文丢失：客户端发送报文之后会启动一个定时器，在超时之后未收到服务器端的确认，客户端会再次发送SYN请求，每次尝试的时间会是第一次的两倍，重传一定次数还未收到回复 ，此次建立连接失败

2.第二次 SYN+ACK 报文丢失：

第二次握手的 SYN+ACK 报文其实有两个目的：

1).第二次握手的ACK，是对第一次握手的确认报文		2).第二次握手里的SYN，是服务端发起同意建立TCP连接的报文

所以第二次握手的报文丢失：

客户端会重传第一次握手的SYN报文，因为客户端没有收到到服务器的回复

服务端则会再一次重传SYN+ACK报文，因为第二次握手的报文需要第三次握手的ACK报文进行确认，你不给我确认我就认为你没收到，我就自动重传

3.第三次握手的ACK报文丢失：

第三次握手的ACK报文丢失，则服务端无法收到确认，则服务端就会短暂处于 SYN_RECV 状态，而客户端就会处于 ESTABLISHED 状态，由于服务端一直收不到第三次握手的ACK，就会一直重传SYN+ACK 包，直到重传次数超过5次就会自动断开连接

附：修改 /proc/sys/net/ipv4/tcp_synack_retries 的值可设置建立连接过程中丢包的超时重传次数，默认是5次



45.TCP三次握手为什么不是两次，四次？四次挥手为什么不是三次？

**答：**两次握手不行，需要三次握手的原因是为了**防止已经失效的连接请求报文突然又传送到了服务端，因而产生错误**

四次握手理论上可以，第二次握手的ACK和SYN分两次发送给客户端；但是三次握手就足以保证通信的可靠性了，没有必要再握一次手

附：四次挥手中间为什么是两次？ 

**答：**关闭连接时，当server端收到FIN报文时，很有可能不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉Client端，"你发的报文我收到了"。只有等我Server端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送，所以中间挥了两次手



52.TCP的超时重传的这个时间怎么确定？ （计网P225）

RRT为报文段的往返时间，RRT(s)为报文段的加权平均往返时间，RTO为超时重传时间，RTT(D)是RTT偏差的加权平均值      (s代表smoothed，RTO : RetransmissionTime-Out )

**答：**发送方发出报文到收到确认报文的这段往返时间称为RRT时间，超时重传的时间应略大于RRT的平均值

具体算法是Karn提出，为：报文段每重传一次，就把超时重传的时间RTO增大一些，新的超时重传时间取为旧的重传时间的2倍；

当不再发生报文段的重传时，取超时重传时间为 RTO = RTT(s) + 4*RTT(D)

超时时间 RTO 设置较大时，重发就慢，丢了包之后老半天才重发，效率低；设置较小时，会导致可能并没有丢就重发，于是重发的就快，会增加网络拥塞，导致更多的超时，更多的超时又导致更多的重发



57.time wait 的2MSL有什么用？  (计网P241)

**答：**两个作用       （回答这个问题最好画出四次挥手流程图）

1.保证A最后发送的一个ACK报文  (确认关闭连接报文 ) 能够到达B，因为这个报文可能丢失，如果丢失B会超时重传FIN+ACK报文，而A就能收到这个重传的报文就再发一次ACK报文给B，B收到后就进入CLOSED状态(关闭状态)； 

如果A发送完最后一个ACK报文不等到time wait时间就立即进入colsed状态，则如果数据包中途丢失，B重传给A的数据包A也就不回复，这样B就无法正常关闭

2.A在发送完最后一个ACK报文后，再经过2MSL时间就可以使本次连接持续的时间内所产生的所有报文段都从网络中消失；这样就可以使下一个新的连接中不会出现旧的连接请求报文段

附：为什么是2MSL?

**答：**比如现在A发送出去了最后一个ACK报文，但中途丢失了；B等待了MSL时间没有收到，就会再发送一次FIN报文，到达A的时间为MSL，而这个等待加上重新发送的时间刚好为2MSL，所以设定的时间为2MSL



20.TCP断开连接的2MSL时间具体为多少？

**答：**Windows下一个MSL时间为2分钟，所以为4分钟

(Ubuntu 和 Centos)一个MSL时间为1分钟			Unix一个MSL时间为半分钟



48.说一说连接过程中的半关闭状态？

**答：**TCP关闭连接过程中当客户端发出请求关闭连接的FIN报文后，服务端收到该报文回复给客户端一个ACK确认报文后就进入了半关闭状态 (也就是colse_wait状态，等待关闭状态)



53.出现大量的 close_wait 状态是什么原因以及怎么解决？

**答：**大量close_wait状态出现只有一种原因：对方在关闭连接后服务器程序没有进一步发出ACK信号；也就说对方关闭连接之后，程序里没有检测到，或者程序根本就忘记了这个时候需要关闭连接，于是这个资源就一直被程序占用着

解决方案：检查服务器程序代码，因为这种情况问题是出现在服务器程序里面

附：如果服务端一直处于close_wait状态，也就是迟迟不给客户端发送第三次挥手的FIN报文，这时客户端是不能监测到的，这种情况客户端会一直等待，也就是只能把服务端这边程序杀掉或者重启才行



58.time wait 状态过多是什么原因，有什么问题以及怎么解决？

**答：**time wait 状态是主动断开TCP连接的一方产生的，客户端处于time wait状态的话问题不大，但是如果服务器产生大量的time wait状态的连接，就会大大降低服务器的响应速度和性能；其**根本原因**是一些端口号和socket地址被占用而得不到释放

危害：第一是占用内存资源；第二是对端口资源的占用，一个TCP连接至少占用一个TCP端口

由于一个四元组 {源IP，目标IP，源端口，目的端口} 表示一个TCP连接，理论上服务端可以建⽴很多连接，服务端确实只监听⼀个端口，但是会把连接扔给处理线程，所以理论上监听的端⼝可以继续监听；但是线程池处理不了那么多⼀直不断的连接了。所以当服务端出现大量 TIME_WAIT 时，系统资源被占满时，会导致处理不过来新的连接

解决方案：

方案一：让每个 time_wait 早点过期，修改MSL时间即可

方案二：端口复用，有一个 tcp_tw_resuse 功能，如果开启了此功能，在调用 connect 时内核会随机找一个 time_wait 超过1秒的连接给新到来的连接复用，有一个 setsocketopt 系统调用可以设置端口复用



附：一般情况下服务器不会进入time wait状态，因为大多数情况都是客户端主动发起连接并关闭；但是某些服务如 pop/smtp, ftp服务确实服务端收到客户端的 quit 命令后主动关闭连接，这就造成服务器上很容易出现大量的 time wait 状态，而且并发量越大此种状态的连接越多



1.TCP延迟确认和Nagle算法 (《小林Coding》P232 )

**答：**当我们TCP报文承载的数据非常小的时候，例如只有几个字节，那么整个网络的效率是很低的，因为每个TCP报文都有20字节的TCP头部，也会有20字节的IP头部，而数据却只有几个字节，所以整个报文中有效数据占有的比重就会非常低

于是就出现了两种策略来减少小报文的传输，分别是：Nagle算法和TCP延迟确认

Nagle算法做了一些策略来避免过多的小报文发送，这可提高传输效率

1.当没有已经发送但还未收到确认的报文时，立即发送数据

2.存在未确认报文时，直到没有发送确认报文或者数据长度达到MSS大小，再发送数据

只有没满足上面的一条，发送方就会一直囤积数据直到满足上面的发送条件



事实上没有携带数据的ACK，它的网络效率也是很低的，因为它有40个字节的IP头和TCP头，但没有携带任何数据报文

TCP延迟确认的策略：

1.当有响应数据要发送时，ACK会随着响应数据一起发送给对方

2.当没有响应数据要发送时，ACK会延迟一段时间，以等待发送端是否有响应数据可以一起发送

3.如果在延迟等待发送ACK期间，对方的第二个数据报文又到达了，这时就会立刻发送ACK



#### UDP通信机制

3.UDP怎么保证能收到数据？

**答：**UDP将可靠传输的实现放到了应用层，然后类似于TCP，实现确认机制，重传机制

UDP不属于连接型协议，因而具有消耗资源小，处理速度快等优点，所以通常音频、视频通话在传送时使用UDP比较多，因为它们即使丢失一两个数据包也不会对结果产生太大影响

UDP传输层无法保证数据的可靠传输，只能通过应用层来实现了；实现的方式可以参考TCP可靠传输的方式，只是实现不在传输层，转移到了应用层

目前有如下开源程序利用UDP实现了可靠的数据传输；分别有RUDP, RTP, UDT



72.UDP的包大小有限制吗？

**答：**在应用程序中我们用到的data的长度最大是多少，直接取决于底层的限制；	从上到下分析：

1.在数据链路层，由以太网的物理特性决定了数据帧的大小为 (18+46)~(18+1500)，其中18是数据帧的帧头和帧尾总大小，也就是说数据帧的内容最大为1500字节(不包括帧头和帧尾)，即MTU为1500字节

2.在网络层，因为IP包的首部要占20字节，所以这里的MTU为：1500-20=1480

3.在传输层：对于UDP包的首部占8字节，所以这里的MTU为：1480-8=1472；对于TCP，首部为20字节，所以MTU为1460

所以在应用层，data的最大长度为1472字节；当我们的UDP包中的数据多于MTU时，发送方的IP层需要分片进行传输，而在接收方的IP层需要进行数据报重组，由于UDP是不可靠的传输协议，如果分片导致重组失败，将导致UDP数据包直接被丢弃



11.UDP和TCP的区别是什么？

**答：**最大的区别就在于UDP是不可靠传输，即UDP是尽最大努力交付，不能保证可靠交付，也没有拥塞控制

　　而TCP是可靠传输，TCP的可靠传输涉及到超时重传机制和滑动窗口机制以及流量控制和拥塞管理

其他的一些差别比如：

1、UDP不需要建立会话，TCP需要建立会话；

2、UDP支持一对一，一对多，多对一的交互通信，因而支持广播，多播，组播；而TCP只能是点到点通信

3、TCP面向字节流，实际上TCP把数据看成一连串无结构的数据流；而UDP是面向报文的，一个一个包的发送，每个数据包有边界，但可能会丢包和乱序

4、TCP的逻辑通信信道是全双工的可靠信道；而UDP则是不可靠信道

5、TCP首部长度较长，会有一定的开销，首部在没有使用「选项」字段时是 20 个字节，如果使用了「选项」字段则会变长的；而UDP首部只有8个字节，并且是固定不变的，开销较小

6、TCP 的数据大小如果大于 MSS 大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装 TCP数据包，如果中途丢失了⼀个分片，只需要传输丢失的这个分片

UDP 的数据大小如果大于 MTU 大小，则会在 IP 层进行分片，目标主机收到后，在 IP 层组装完数据，接着再传给传输层，但是如果中途丢了⼀个分片，在实现可靠传输的 UDP 时则就需要重传所有的数据包，这样传输效率非常差，所以通常 UDP 的报文应该小于 MTU

附：单播，多播(组播)，广播的区别

单播：主机给每个目标主机一个广播包				

多播 (组播)：主机给每一组主机发送一个广播包

广播：主机发送一个广播包，所有主机都能收到



50.TCP和UDP各自的应用，举例子

**答：**传输大文件，像电影，视频什么的都是使用的TCP协议，因为一个数据包不能全部传完

像域名解析这些发一个数据包就能把数据全部传完的就是使用的UDP协议；因为TCP是点到点通信，所以多播，广播使用的都是UDP协议

因为TCP是面向连接，并且能够保证数据的可靠交付，因此经常用于FTP文件传输，HTTP/HTTPS等

而 UDP 面向无连接，它可以随时发送数据，再加上UDP本身的处理既简单又高效，所以经常用于

1.包总量较少的通信，如DNS，SNMP等

2.视频、音频等多媒体通信  ( 因为这些通信追求的是效率，数据包越快送达越好，而且即使丢失一两个数据包也不会造成太大影响 )

3.广播，多播通信



61.UDP会发生粘包吗？	62.粘包原因是什么？粘包问题怎么解决？     （参看CSDN博客）

**答：**TCP是传输层的协议，传输层除了有TCP协议还有UDP协议；但是UDP不会发生粘包，因为UDP是基于报文发送的，从UDP的帧结构可以看出，在UDP首部采用了16Bit来表示UDP报文的长度，因此应用层能很好的将不同的数据报文区分开来，从而避免粘包和拆包的问题；而TCP是基于字节流的，虽然应用层和TCP传输层之间的数据交互是大小不等的数据块，但是TCP把这些数据块都看成一连串无结构的字节流，没有边界；另外从TCP的帧结构也可以看出，在TCP的首部没有表示数据长度的字段，所以TCP在传输时才有可能发生粘包或者拆包

原因：1.要发送的数据大于TCP缓冲区剩余空间大小，将会发生拆包

2.待发送数据大于MSS(最大报文长度)，TCP在传输前进行拆包

3.要发送的数据小于TCP缓冲区的大小，TCP将多个写入缓冲区的数据一起发送出去，将会发生粘包

4.接收端的应用层程序没有及时读走缓冲区的数据，将发生粘包



解决方案：1.发送端给每个数据包添加的包首部中至少应该包含数据包的长度，这样接收端在接收到数据后，通过读取包首部的长度字段，便知道每个数据包的实际长度

2.发送端将每个数据包封装为固定长度(不够的可以通过补0填充)，这样接收端每次从缓冲区中读取固定长度的数据就自然而然的把每个数据包拆分开来

3.可以在数据包中设置边界，比如添加特殊符号，这样接收端就可以通过这个边界将不同的数据包拆分开来

简而言之：TCP粘包就是发送方发送的多个数据包，到接收方缓存区首尾相连，粘成一个包被接收



#### TCP异常断开机制：

##### 1.client 端与 server 端建立长连接 ( 即开启了keep-alive)，第一种情况服务器直接挂了，第二种情况服务器进程挂了，两种情况下client端会做出什么反应？

**答：**

1）服务器进程挂掉了，则无论有没有开启长连接，且也无论双方有没有数据交互，这个过程操作系统是可以感知到的，于是就会发送FIN报文给对方，然后与对方进行TCP四次挥手断开连接

附：如果是正常关机，系统会向各个进程发送 SIGTERM 和 SIGKILL 信号，server进程会退出，然后关闭相应的文件描述符，给对应的 client 端发送 FIN 消息

2）服务器直接挂掉了

1.开启了TCP的 keep-alive 且有数据交互

**答：**此时 client 端发出数据后，会一直阻塞在套接字的读取响应，但是由于服务器主机已经崩溃，TCP客户端会持续重传数据分组，试图从服务器接受一个ACK(一般重传15次) 后，客户端TCP最终选择放弃，返回给客户端应用进程一个ETIMEDOUT错误；或者是因为中间路由器判定服务器主机不可到达，则返回一个目标主机不可到达的ICMP消息响应

2.开启了TCP的 keep-alive 但是没有数据交互

**答：**TCP还设有一个保活计时器(keepalive timer)；当客户端和服务器建立连接之后如果客户端的主机突然出现故障 (或者服务端的主机出现故障)，服务器就不能再白白浪费时间等待客户端主机；这时就需要使用保活计时器，服务器每收到一次客户的数据，就重新设置保活计时器，时间的设置通常是两个小时；若两个小时没有收到客户端发来的数据，服务器就发送一个探测报文段，以后每隔固定时间就发送一次；若一连发送好几个探测报文段后客户端仍没有反应，则服务器就认为客户端出现了差错，就主动关闭该连接     （计网P241）

在Linux内核中可以有对应的参数来设置保活时间，保活探测的次数，保活探测的时间间隔

保活时间默认为两小时，保活探测次数默认为9次，保活探测的间隔时间默认为75秒；也就是Linux系统中最少需要2小时11分15秒才可以发现一个死亡的连接；TCP的保活机制可以在双方没有数据交互的情况下，通过探测报文来检测对方的TCP连接是否还存活

保活探测报文的发送会有以下几种情况：

1、对端程序正常工作；当TCP保活的探测报文发送给对端，对端能够正常响应，这样TCP的保活时间会被重置，等待下一个保活时间的到来

2、对端程序程序崩溃并重启；当TCP保活的探测报文发送给对端后，对端是可以响应的，但是由于没有该连接的有效信息，会产生一个RST报文，这样很快就会发现TCP连接已被重置

3、对端程序崩溃；达到保活探测次数后就主动关闭连接



##### 3.在没有开启TCP的 keep-alive 的情况下，且**双方存在数据交互**，如果客户端的主机崩溃(宕机)了，会发生什么？

**答：**客户端主机崩溃了，服务端是无法感知到的，在加上服务端没有开启 TCP keepalive，又没有数据交互的情况下，服务端的 TCP 连接将会一直处于 ESTABLISHED 连接状态，直到服务端重启进程；所以，我们可以得知在没有使用 TCP 保活机制且双方不传输数据的情况下，一方的 TCP 连接处在 ESTABLISHED 状态，并不代表另一方的连接还一定正常



##### 4.在没有开启TCP的keep-alive的情况下，且**双方存在数据交互**，如果客户端的主机崩溃(宕机)了，会发生什么？

**答：**这种情况，服务端超时重传报文的次数达到阈值后，内核就会判定出该 TCP 有问题，然后通过 Socket 接口告诉应用程序该 TCP 连接出问题了，一般就是 ETIMEOUT 状态码

具体重传几次？

在 Linux 系统中，提供一个叫 tcp_retries2 配置项，默认值是 15，这个内核参数是控制在 TCP 连接建立的情况下，超时重传的最大次数

不过 tcp_retries2 设置了 15 次，并不代表 TCP 超时重传了 15 次才会通知应用程序终止该 TCP 连接，内核还会基于「最大超时时间」来判定；每一轮的超时时间都是倍数增长的，比如第一次触发超时重传是在 2s 后，第二次则是在 4s 后，第三次则是 8s 后，以此类推。

内核会根据 tcp_retries2 设置的值，计算出一个最大超时时间，在重传报文且一直没有收到对方响应的情况下，先达到「最大重传次数」或者「最大超时时间」这两个的其中一个条件后，就会停止重传



附：如果客户端主机宕机又迅速重启呢？

**答：**在客户端主机宕机后，服务端向客户端发送的报文会得不到任何的响应，在一定时长后，服务端就会触发超时重传机制，重传未得到响应的报文；服务端重传报文的过程中，客户端主机重启完成后，客户端的内核就会接收重传的报文，然后根据报文的信息传递给对应的进程

1).如果客户端主机上没有进程监听该 TCP 报文的目标端口号，那么客户端内核就会回复一个 RST 报文，重置该 TCP 连接；

2).如果客户端主机上有进程监听该 TCP 报文的目标端口号，由于客户端主机重启后，之前的 TCP 连接的数据结构已经丢失了，客户端内核里协议栈会发现找不到该 TCP 连接的 socket 结构体，于是就会回复 RST 报文，重置该 TCP 连接

所以，只要有一方重启完成后，收到之前 TCP 连接的报文，都会回复 RST 报文，以断开之前的连接



总结：各种异常下的数据报重传次数总结

TCP建立连接过程中的数据包的重传次数默认为5次

TCP建立连接后的数据包传输的默认重传次数为15次

若没有数据交互，达到TCP的保活时间后保活探测报文段的默认重传次数为9次，每次间隔75秒



##### 70.TCP的 keep-alive 和HTTP的 keep-alive       

Http的 keep-alive 称为长连接，TCP的 keep-alive 称为保活计时器

**答：**我们知道 Http 协议采用“请求-应答”模式，当使用普通模式，即非 Keep-Alive 模式时，每个请求/应答，客户端和服务器都要新建一个连接，完成之后立即断开连接；当使用 Keep-Alive 模式时，Keep-Alive 功能使客户端到服务器端的连接持续有效，当出现对服务器的后继请求时，Keep-Alive 功能避免了建立或者重新建立连接

开启 Keep-Alive 的优缺点：

优点：Keep-Alive 模式更加高效，因为避免了连接建立和释放的开销

缺点：长时间的 TCP 连接容易导致系统资源无效占用，浪费系统资源



附：当 HTTP 保持长连接时，如何判断一次请求已经完成？

**答：**使用 Content-Length 字段

Content-Length 表示实体内容的长度；浏览器通过这个字段来判断当前请求的数据是否已经被全部接收

所以，当浏览器请求的是一个静态资源时，即服务器能明确知道返回内容的长度时，可以设置Content-Length来控制请求的结束。但当服务器并不知道请求结果的长度时，如一个动态的页面或者数据，Content-Length就无法解决上面的问题，这个时候就需要用到 Transfer-Encoding 字段

Transfer-Encoding 是指传输编码，在上面的问题中，当服务端无法知道实体内容的长度时，就可以通过指定 Transfer-Encoding: chunked 来告知浏览器当前的编码是将数据分成一块一块传递的。当然, 还可以指定Transfer-Encoding: gzip, chunked表明实体内容不仅是 gzip 压缩的，还是分块传递的。最后，当浏览器接收到一个长度为 0 的chunked时，就知道当前请求内容已全部接收



Keep-Alive timeout：

Httpd 守护进程，一般都提供了 keep-alive timeout **时间设置参数**；比如 nginx 的 keepAlive_timeout，和Apache的KeepAliveTimeout；这个 keepalive_timout 时间值意味着：一个http产生的 tcp 连接在传送完最后一个响应后，还需要 hold 住 keepalive_timeout 秒后，才能真正关闭这个连接

当 httpd 守护进程发送完一个响应后，理应马上主动关闭相应的 tcp 连接，设置 keepalive_timeout 后，httpd守护进程会想说：”再等等吧，看看浏览器还有没有请求过来“，这一等，便是keepalive_timeout 时间。如果守护进程在这个等待的时间里，一直没有收到浏览器发过来的 http 请求，则关闭这个http连接



##### 71.TCP的半连接，半打开，半关闭

半连接：未成功建立三次握手的连接都叫半连接

半关闭：TCP四次挥手过程中当服务端发出第二次挥手的报文时便进入半关闭状态，也就是 close_wait 状态

半打开：如果TCP连接中一方已经关闭或者异常终止连接，但是另外一方却不知道，则称这样的TCP连接为半打开







## 网络层

网络层功能：负责为数据包选择转发路径以及IP数据包的分片和转发，不负责可靠传输，也不负责按顺序到达

#### IP地址和MAC地址

37.IP地址和MAC地址的区别和作用？

**答：**MAC地址是一个硬件地址，也叫物理地址，使用其来定义网络设备的位置；MAC地址是数据链路层和物理层使用的地址，主要由数据链路层负责；

而 IP 地址是 IP 协议提供的一种统一的地址格式，为互联网上的每一个网络和每一台主机分配一个逻辑地址，**以此来屏蔽物理地址的差异**；IP地址是网络层及其以上层使用的地址

因为 IP 地址对于最底层的网络通讯硬件是不可见的 ( 也就是在物理层和数据链路层IP地址是不可见的，即识别不出来这个东西)，这时候就需要按照物理地址来进行数据转发



附：1.交换机基于数据帧的MAC地址转发数据帧，路由器基于数据包的IP地址转发数据包

2.数据包在传输过程中不变，经过网络设备时数据帧就要用新的物理地址重新封装

3.MAC地址决定了数据帧的下一跳由哪个设备来接收，而IP地址决定了数据包的起点和终点



问：为什么不直接用MAC地址进行通讯？

**答：**由于全世界存在着各式各样的网络，它们使用不同的硬件地址。要使这些异构网络能够互相通信就必须进行非常复杂的硬件地址转换工作，因此几乎是不可能的事

而连接到 Internet 的主机都拥有统一的IP地址，它们之间的通信就像连接在同一个网络上那样简单方便，因为使用ARP协议来寻找某个路由器或主机的硬件地址都是由计算机软件自动进行的，对用户来说看不见这种调用过程



5.最大传输单元 ( MTU ) 和最大报文段长度 ( MSS )

**答：**以太网的数据链路层的最大传输单元是1500字节，当 IP 数据包大于1500字节时，IP数据包就会被分片，经过分片后的IP数据包在重组的时候只能由目标主机进行，路由器是不会进行重组的，在分片传输过程中，一旦某个分片丢失，则会造成整个IP数据报作废，所以TCP引入了MSS也就是在TCP层进行分片而不由IP层进行

而对于UDP我们尽量不要传输一个大于MTU的数据报文



22.IPv4和IPv6差别

**答：**1.IPv4是32位的，大约可以提供42亿个地址；IPv6是128位的，可分配的地址数非常大，IPv4以每8位作为一个一组，采用点分十进制的方式表示；IPv6每16位作为一组，采用16进制表示，每组用冒号 ":" 隔开

2.IPV6支持即插即用功能；即使没有DHCP服务器也能够自动分配IP地址

3.认证与加密功能：有应对伪造IP地址的网络安全功能以及防止线路窃听的功能，更加安全

4.性能提升（从数据包首部字段方面看）

1). 包首部长度采用固定的40个字节来表示，**不再采用首部校验码**；简化首部结构，减轻路由负荷

2). 路由器不再做分片处理，数据包分片只能由发送端进行；取消分片后，IPV6首部**不再有数据包标识以及标志和片偏移等字段**

3). **取消选项字段**，选项字段不再是标准IP首部的一部分，但它并没有消失，取而代之的是使用扩展首部，当需要对数据报分片时，可以使用扩展首部；IPV4的选项长度最大只能为40字节，但是IPV6的扩展首部长度可以是任意长度 ，没有具体的大小限制  （图解TCP/IP P154）

附：IPv4和IPv6不能互相兼容，所以不但要我们电脑，手机之类的设备支持，还需要网络运营商对现有的设备进行升级，这可能是IPv6普及比较慢的原因



30.IP地址的编码分为哪两部分？ 

**答：**网络部分和主机部分；依据子网掩码来区分哪些是网络位哪些是主机位

子网掩码常用的有三种，分为A，B，C 三类地址

子网掩码为255.0.0.0  则是A类IP地址，第一段８位为网络位，后三段为主机位

子网掩码为255.255.0.0  则是B类IP地址，网络位和主机位各为两段

子网掩码为255.255.255.0  则是C类IP地址，网络位为三段，主机位为一段

附：A类地址的网络最高位必须是0，范围从1.0.0.1到127.255.255.254 ；数字0和数字127不能作为A类地址，数字127代表本地回环地址，而数字0代表该地址是本地宿主机；主机位全为0代表的是本网段，主机位全为1代表的是广播地址

B类地址的网络最高位必须是10，范围从 128.0.0.1 到 191.255.255.254

C类地址的网络最高位必须是110，范围从 192.0.0.1 到 223.255.255.254



19.某公司申请到一个C类IP地址，但要连接6个子公司，最大的一个子公司有26台计算机，每个子公司分别在一个网段中，则子网掩码应该设为？

**答：**由于2^4 < 26 < 2^5  则第子网掩码第四段位为11100000  故子网掩码为 255.255.255.224



20.与10.110.12.29 mask 255.255.255.224 属于同一网段的IP地址是？

A.10.110.12.0  B.10.110.12.30  C.10.110.12.31  D.10.110.12.32

**答：**由于子网第四段位为224，则主机部分为00000  由于主机部分不能为全0或全1则IP地址范围为 10.110.12.(1~30)   故选B

如果主机号全为0，IP地址仅仅代表网络号指向的那个网段，该IP代表一个网段；如果主机号全为１则代表网络号指向的全部主机



在TCP/IP协议中，专门保留了三个IP地址作为私有地址 (也称内网IP)

10.0.0.0 /8：10.0.0.0 ~ 10.255.255.255

172.16.0.0 /12：172.16.0.0 ~ 172.31.255.255

192.168.0.0 /16：192.168.0.0 ~ 192.168.255.255



内网IP想要与外网通信需要使用NAT地址转换技术，把私有IP转换成公有IP地址

但是为了区分内网内的不同地址，现在都是把网络地址和端口一起转换掉，也称为NAPT转换，多个私有地址可以转换成一个唯一的共有地址，但是以不同的端口号来进行区分

路由器会自动生成一个转换表，比如在进行TCP连接时，建立TCP连接首次握手时的SYN包一经发出，就会生成这个表；而后又会随着收到关闭连接时发出 FIN 包的确认应答从表中删除

NAT转换的缺点：由于NAT/NAPT都依赖自己的转换表

1.外部无法主动与NAT内部服务器建立连接，因为NAPT转换表无转换记录

2.转换表的生成与转换操作都会产生性能开销

3.通信过程中，如果NAT路由器重启了，则所有的TCP连接都将会被重置

解决方法：

1.直接使用IPV6

2.NAT穿透技术：就是客户端主动从NAT设备来获取公有IP地址，然后自己建立端口映射条目，然后用这个条目来进行与外界通信，这样就不需要利用NAT设备来进行转换了



#### 网络层协议

##### 1.ARP协议的作用为？

**答：**在网络上通过广播的形式 (即发送广播包) 解析目标IP地址主机的MAC地址；但只能解析本网段的主机MAC地址；跨不了路由器

在传输一个数据报的时候，确定了源IP和目标IP后，就会通过主机路由表确定IP数据包下一跳；然而网络的下一层是数据链路层，所以我们还需要知道下一跳的ＭAC地址；	(小林Coding P343)

由于主机的路由表中可以找到下一跳的IP地址，所以可以通过ARP协议找到下一跳的MAC地址

ARP协议就是借助ARP请求和ARP响应两种类型的包来确定MAC地址的

1.主机会通过广播发送ARP请求，这个包中包含了想要知道的MAC地址的IP地址

2.当同个链路中的所有设备收到ARP请求时，会去拆开ARP请求包中的内容，如果ARP请求包的目标IP地址和自己的IP地址一致，那么这个设备就将自己的MAC地址塞入到ARP响应包返回给主机

操作系统通常会把第一次ARP获取的MAC地址缓存起来，以便下次直接从缓存中找到对应IP地址的MAC地址



##### 2.ICMP的作用？ 

**答：**ICMP ( 网际报文控制协议 ) 的功能主要包括：确认IP包是否成功送达目标地址，以及报告发送过程中的IP包被废弃的原因和改善网络设置等，有了这些功能以后，就可以获得网络是否正常，设置是否有误以及设备有何异常等信息，从而便于进行网络上的问题诊断；在IP通信中如果某个IP包因为某种原因未能到达目标地址，那么这个具体的原因将由 ICMP 负责通知		 (小林Coding P352)     

ICMP大致可分为两种类型： 一类用于诊断的查询消息，也就是查询报文类型；另一类是通知出错原因的错误消息，也就是差错报文类型

比如：0 代表回送应答 (Echo Replay) 	 8 代表回送请求(Echo Request)  	 3 代表目标不可到达  	 11 代表超时     5 代表重定向或改变路由



查询报文类型：类型0和类型8代表回送消息

回送消息用于通信的主机或者路由器之间，判断所发送的数据报是否已经成功到达对端的一种消息，ping命令就是利用这个消息实现的



差错报文类型：类型3 代表目标不可到达   	类型11 代表超时消息（TTL减少到0时路由器就会发送一个ICMP超时消息给发送端主机）

IP路由器无法将IP数据包发送给目标地址时，就会给发送端返回一个目标不可到达的ICMP消息，并在这个消息中显示不可到达的原因，原因记录在ICMP包头的代码字段

ICMP目标不可到达的代码号 (类型3的细分)

0  网络不可到达  （当路由表匹配不到接收方 IP 的网络号）

1  主机不可到达  （当路由表没有该主机，或者该主机没有直连到网络）

2  协议不可到达  （比如发送方使用TCP协议，但是接收方防火墙禁止TCP协议访问）

3  端口不可到达    (对方主机没有进程监听该端口)

4  需要进行分片但设置了不分片



ping命令主要利用的是 ICMP 里面的 (Echo Request)类型为8 和 (Echo Replay)类型为0的两种消息

主机A ping 主机B时，主机A会发送一个ICMP回送请求的数据包，这个数据包里面有很多内容，主要有报文类型 (回送请求类型自然为8)，序号 (用于ping的时候发出的多个数据包)，以及数据包的发送时间 (这是为了计算出数据包的往返时间RTT)

主机 B 如果正常收到请求报文后，会构建一个ICMP回送响应消息数据包，该数据包的类型字段为0，序号为接收到的请求数据包中的序号，然后再发送给主机A

如果不能正常接收，由中途的路由器返回数据包不能到达的原因



附：有一款利用ICMP差错报文类型的应用叫做 traceroute

作用一：故意设置特殊的TTL，来追踪去往目的地时沿途经过的路由器数，它的原理就是利用IP包的生存周期从1开始按照顺序递增的同时发送UDP包，强制接受ICMP超时消息的一种方法，TTL数值从１逐渐增大的发包，直到返回正确的响应报文就可以知道目标主机离我们有多少个路由器了

作用二：故意设置不分片，用来确定路径的MTU，因为有的时候我们并不知道路由器的MTU大小，以太网的数据链路层的MTU通常是1500字节，但是非以太网的MTU就不一样了， 所以我们要知道MTU的大小，从而控制包的大小



##### 3.当路由器接收到的IP报文的TTL的值为1时，采取的策略为？

**答：**经过该路由器TTL的值就变成0了，所以路由器会丢掉该数据包

附：不同系统的TTL值

Linux和Unix是64     Windows是128     Solaris是254



##### 4.VLAN的主要作用有哪些？  

**答：**VLAN ( Virtual Local Area Network) 虚拟局域网，是将一个物理上的 LAN 在逻辑上划分成多个广播域的通信技术；( 计网P101有简单介绍）

VLAN的作用有以下几点：

1.限制广播域：广播域限制在一个 VLAN 中，节省了带宽，提高了网路的处理能力

2.增强局域网的安全性：不同 VLAN 内的报文在传输时是相互隔离的，即一个 VLAN 内的用户不能和其他VLAN内的用户直接通信

3.提高网络的健壮性：故障被限制在一个 VLAN 中，本 VLAN 中的故障不会影响到其他 VLAN 的正常工作

4.灵活构建虚拟工作组：用 VLAN 可以划分不同的用户到不同的工作组，同一工作组的用户也不必局限于某一固定的物理范围，网络构建和维护更加方便



##### 5.BGP和OSPF协议的区别

**答：**动态路由协议可分为内部网关协议和外部网关协议，内部网关协议有RIP, OSPF, IS-IS协议，外部网关协议有BGP

RIP(Routing Infomation Protocol) 路由信息协议    OSPF(Open Shortest Path First) 最短路径优先协议     这两个协议都是选路协议

RIP协议每隔 30s 就送出自己完整的路由表到所有激活的窗口，**RIP协议选择最佳路径的标准是跳数**，认为到达目标网络经过的路由器最少的路径就是最佳路径，默认其所允许的最大跳数为15跳，也就是说16跳的距离会被认为是不可到达的，所以RIP协议只适用于小型网络；

OSPF特性如下，(OSPF协议选择最佳路径的标准是带宽，带宽越高计算出的开销越低；到达目标网络的各个链路累计开销最低的就是最佳路径)  

![](C:\Users\12458\Desktop\Typora\PNG\Image23 [2].png) 

BGP (Border Gateway Protocol) 边界网关协议用于处理各ISP之间的路由传递；BGP是一种外部网关协议，与内部网关协议(EGP)不同的是，其关注点不在于发现和计算路由，而在于控制路由的传播和选择最佳路由；BGP协议具有如下特点

![](C:\Users\12458\Desktop\Typora\PNG\Image24.png) 

注：AS(Autonomous System) 自治系统

自治系统：一片网络归一个单位或者一个运营商来维护，这就是一个自治系统



#### 网络层设备

##### 1.路由器作为网络互联设备，必须具备哪些特点？9.路由器的作用有哪些?

**答：**1.网络互联：路由器支持各种局域网和广域网的接口，主要用于互联局域网和广域网，实现不同网络间的通信

2.数据处理：路由器提供分组过滤、分组转发、优先级、复用、加密、压缩和防火墙等功能

3.网络管理：路由器提供包括路由表的配置管理、性能管理、容错管理和流量控制等功能



##### 2.路由器和交换机的区别

**答：**路由器是基于 IP 设计的，位于网络层，俗称三层网络设备，路由器的各个端口都具有 MAC 地址和 IP 地址；

交换机是基于以太网设计的，位于数据链路层，俗称⼆层网络设备，交换机的端口不具有 MAC 地址

路由器的端口具有 MAC 地址，因此它就能够成为以太网的发送方和接收方；同时还具有 IP 地址，从这个意义上来说，它和计算机的网卡是⼀样的；当转发包时，首先路由器端口会接收发给自己的以太网包，然后路由表查询转发目标，再由相应的端口作为发送方将以太网包发送出去

交换机能够学习到路由表，而且交换机的网口能够存储数据帧(可以存储转发)；用交换机组网可以是全双工通信；交换机是端口带宽独享，不像集线器是端口带宽共享，而且交换机是基于MAC地址转发数据，更加安全；交换机通常用于同一网段内的主机之间通信









